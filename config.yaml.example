# CrawlSmith Configuration File
# Copy this file to config.yaml and update with your settings

server:
  port: 8080
  host: localhost
  read_timeout: 30s
  write_timeout: 30s

crawler:
  max_depth: 10
  max_pages_per_domain: 1000
  requests_per_second: 10
  user_agent: "CrawlSmith/1.0 (+https://github.com/amosWeiskopf/crawlsmith)"
  timeout: 30s
  follow_robots_txt: true
  extract_contacts: true
  enable_javascript: false
  max_workers: 10

apis:
  openai:
    # Set via OPENAI_API_KEY environment variable
    api_key: ""
    model: "gpt-4"
    max_tokens: 2000
    temperature: 0.7
  
  dataforseo:
    # Set via DATAFORSEO_LOGIN and DATAFORSEO_PASSWORD environment variables
    login: ""
    password: ""
    endpoint: "https://api.dataforseo.com"
  
  serpapi:
    # Set via SERPAPI_API_KEY environment variable
    api_key: ""

storage:
  type: "file" # Options: file, database, s3
  path: "./data"
  batch_size: 100

logging:
  level: "info" # Options: debug, info, warn, error
  format: "json" # Options: json, text
  output_path: "stdout" # Options: stdout, stderr, or file path